---
title: "ARTIFICIAL INTELLIGENCE IN SOCIETY"
date: 2020-12-01T19:11:22+02:00
draft: true
---
## I.	ARTIFICIAL INTELLIGENCE IN SOCIETY

1. Introducton
2. A short history of artificial intelligence
3. Current situation in the field of Artificial intelligence, blockchain and quantum computing 
4. AI-powered responses to combat COVID-19 
5. Artificial intelligence in society
6. AI applications
	- AI in the public sector 
	- AI in agriculture
	- AI in marketing and advertising 
	- AI in science 
	- AI in health 
	- AI in criminal justice 
	- AI in security 
7. International co-operation
8. Quantum computing 

## I.	ARTIFICIAL INTELLIGENCE IN SOCIETY
### 1. Introducton
Artificial intelligence While the development of national policies on AI is relatively new, countries have set ambitious targets. This section examines trends in national AI strategies and policies, which aim to support innovation and the development and adoption of AI systems that are trustworthy and human-centred. It builds on data and evidence from the OECD AI Policy Observatory (www.oecd.ai). AI policy initiatives are structured according to the 2019 OECD Recommendation of the Council on Artificial Intelligence (hereafter “the OECD AI Principles”) (OECD, 2019[1]). First, they draw on the five values-based principles for the responsible stewardship of trustworthy AI. Second, they refer to policy recommendations pertaining to national policies and international co-operation for trustworthy AI. 
AI promises to increase the efficiency and effectiveness of entire sectors, including the delivery of public services. 

Applied wisely, AI can improve well-being in areas like education, public safety and health. It can also help address pressing global problems, such as climate change and wider access to health care and mobility. Governments are planning to invest in and develop AI for its many benefits. 

Yet alongside benefits, AI raises new or heightened types of ethical and fairness concerns. Chief among them are questions of respect for human rights and democratic values, and the dangers of transferring biases from the analogue into the digital world. Designing systems that are transparent about the use of AI and accountable for their outcomes is critical. AI systems must function properly and in a secure and safe manner. 

National AI policies must build on international agreements. Over 40 governments signed up to the OECD AI Principles in May 2019, thereby agreeing to ensure trustworthy, human-centred AI systems. National policies are needed to put these principles into action, including those that encourage investment in responsible AI research and development (R&D).

In addition to AI technology and computing capacity, AI leverages vast quantities of data. This increases the need for a digital environment that enables access to data, alongside strong personal data and privacy protections, notably for systems that use sensitive personal data. 
AI-enabling ecosystems can also support SMEs as they navigate the AI transition and ensure a competitive environment. AI will change the nature of work as it replaces and alters components of human labour. Policies will need to facilitate transitions as people move from one job to another, and ensure continuous education, training and skills development.

### 2.A short history of artificial intelligence 

In 1950, British mathematician Alan Turing published a paper on computing machinery and intelligence (Turing, 1950[1]) posing the question of whether machines can think. He developed a simple heuristic to test his hypothesis: could a computer have a conversation and answer questions in a way that would trick a suspicious human into thinking the computer was actually a human?1 The resulting “Turing test” is still used today. That same year, Claude Shannon proposed the creation of a machine that could be taught to play chess (Shannon, 1950[2]). The machine could be trained by using brute force or by evaluating a small set of an opponent’s strategic moves (UW, 2006[3]). Many consider the Dartmouth Summer Research Project in the summer of 1956 as the birthplace of artificial intelligence (AI). At this workshop, the principle of AI was conceptualised by John McCarthy, Alan Newell, Arthur Samuel, Herbert Simon and Marvin Minsky. While AI research has steadily progressed over the past 60 years, the promises of early 
AI promoters proved to be overly optimistic. This led to an “AI winter” of reduced funding and interest in AI research during the 1970s. 

New funding and interest in AI appeared with advances in computation power that became available in the 1990s (UW, 2006[3]). Figure 1.1 provides a timeline of AI’s early development.

Where we are today Over the past few years, the availability of big data, cloud computing and the associated computational and storage capacity and breakthroughs in an AI technology called “machine learning” (ML), have dramatically increased the power, availability, growth and impact of AI. Continuing technological progress is also leading to better and cheaper sensors, which capture more-reliable data for use by AI systems. The amount of data available for AI systems continues to grow as these sensors become smaller and less expensive to deploy.
The result is significant progress in many core AI research areas such as: 
- natural language processing 
- autonomous vehicles and robotics
- computer vision 
- language learning. 

Some of the most interesting AI developments are outside of computer science in fields such as health, medicine, biology and finance. In many ways, the AI transition resembles the way computers diffused from a few specialised businesses to the broader economy and society in the 1990s. It also recalls how Internet access expanded beyond multinational firms to a majority of the population in many countries in the 2000s. Economies will increasinglyneed sector “bilinguals”. These are people specialised in one area such as economics, biology or law, but also skilled at AI techniques such as ML. The present chapter focuses on applications that are in use or foreseeable in the short and medium term rather than possible longer-term developments such as artificial general intelligence (AGI)

### 3. Current situation in the field of Artificial intelligence, blockchain and quantum computing 

Key findings

By June 2020, over 60 countries had developed a national AI strategy or policies on AI and others were following. Countries were promoting AI research and development, data access and skills. At the same time, they were exploring approaches to ensure trustworthy AI and to mitigate risks associated with AI systems. 
Investment and research on artificial intelligence (AI) have been growing fast in recent years. 

The total number of AI-related scientific publications quadrupled over 1999-2019, mainly driven by the United States, the People’s Republic of China (hereafter “China”) and the European Union. AI-related scientific publications co-authored by the United States and China more than doubled between 2014 and 2020. 

Countries are using AI tools widely to help monitor and predict the spread of COVID-19 in real time, speed diagnosis and search for treatments at an unprecedented pace and scale. 

Distributed ledger technologies (DLTs) offer a new way of securing data and transaction records for use by multiple parties without reliance on a trusted, central authority. Among DLTs, blockchain has gained fast notoriety in financial markets. However, countries are developing DLT-based solutions in a wider range of activities, including transport, energy and government services. 

Several countries (e.g. Australia, China, Germany, India and Switzerland) have recently issued some blockchain strategy, while others (e.g. France and Italy) are developing it. International initiatives, like the OECD Blockchain Policy Centre, aim to help governments better understand this technology, address the challenges raised by DLTs and their applications, and seize opportunities to achieve policy objectives and deliver more effective government services. 

Quantum computing brings the promise of addressing computational problems that are intractable on any classical computer. 

It could also accelerate innovation in a wide range of areas, including agriculture, drug development and energy, as well as auto and airplane manufacturing. 
Research on quantum technologies is a global field. The three leaders are the United States (quantum computing), Europe (quantum mechanics) and China (quantum communication and cryptography).

### 4. AI-powered responses to combat COVID-19 

Before the world was even aware of the threat posed by COVID-19, AI systems had detected the outbreak of an unknown type of pneumonia in China. AI technologies and tools were employed to support efforts of policy makers, the medical community and society at large to manage every stage of the pandemic crisis management and its aftermath (Figure 11.2): 1. understanding the virus and accelerating medical research on drugs and treatments 2. detecting and diagnosing the virus, and predicting its evolution 3. assisting in preventing or slowing the spread of the virus through surveillance and contact tracing 4. responding to the health crisis through personalised information and learning 5. monitoring the recovery and improving early warning tools.
AI tools and techniques helped policy makers and the medical community understand the COVID-19 virus and accelerate research on treatments by rapidly analysing large volumes of research data. AI text and data mining tools were used to help uncover the history, transmission and diagnostics of the virus, as well as management measures and lessons from previous epidemics. 

Deep learning models helped predict old and new drugs or treatments to treat COVID-19. DeepMind and others used deep learning to predict the structure of COVID-19 proteins. 
Dedicated platforms and access to datasets in epidemiology, bioinformatics and molecular modelling enabled AI experts to contribute to medical research. By October 2020, the COVID-19 Open Research Dataset Challenge by the US government and partners had made over 200 000 research articles on coronavirus available via a dedicated Kaggle platform. 

Computing power for AI was made available by technology companies; by individuals donating processing power (e.g. Folding@home); and by public-private efforts such as Microsoft’s AI for Health programme and the COVID-19 High Performance Computing Consortium. Innovative approaches such as hackathons, prizes and open source collaborations helped accelerate research by seeking ideas on using AI to control and manage the pandemic, e.g. in the United Kingdom’s CoronaHack – AI vs. COVID-19.

Source: [OECD Digital Economy Outlook 2020](https://doi.org/10.1787/bb167041-en)

### 5. Artificial intelligence in society

AI is reshaping economies, promising to generate productivity gains, improve efficiency and lower costs. It contributes to better lives and helps people make better predictions and more informed decisions. These technologies, however, are still in their infancy, and there remains much promise for AI to address global challenges and promote innovation and growth. As AI’s impacts permeate our societies, its transformational power must be put at the service of people and the planet.
Machine learning, big data and computing power have enabled recent AI progress.

The artificial intelligence (AI) technical landscape has evolved significantly from 1950 when Alan Turing first posed the question of whether machines can think. Coined as a term in 1956, AI has evolved from symbolic AI where humans built logic-based systems, through the AI “winter” of the 1970s to the chess-playing computer Deep Blue in the 1990s. Since 2011, breakthroughs in “machine learning” (ML), an AI subset that uses a statistical approach, have been improving machines ability to make predictions from historical data. The maturity of a ML modelling technique called “neural networks”, along with large datasets and computing power, is behind the expansion in AI development. 
AI systems predict, recommend or decide an outcome to influence the environment. 

An AI system, as explained by the OECD’s AI Experts Group (AIGO), is a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations or decisions influencing real or virtual environments. It uses machine and/or human-based inputs to perceive real and/or virtual environments; abstract such perceptions into models (in an automated manner e.g. with ML or manually); and use model inference to formulate options for information or action. AI systems are designed to operate with varying levels of autonomy. The AI system lifecycle phases are i) planning and design, data collection and processing, and model building and interpretation; ii) verification and validation; iii) deployment; and iv) operation and monitoring. An AI research taxonomy distinguishes AI applications, e.g. natural language processing; techniques to teach AI systems, e.g. neural networks; optimisation, e.g. one-shot-learning; and research addressing societal considerations, e.g. transparency. 
AI can improve productivity and help solve complex problems 

The AI economic landscape is evolving as AI becomes a general-purpose technology. Through cheaper and more accurate predictions, recommendations or decisions, AI promises to generate productivity gains, improve well-being and help address complex challenges. Leveraging AI requires complementary investments in data, skills and digitalised workflows, as well as changes to organisational processes. Therefore, adoption varies across companies and industries. 

I investment and business development are growing rapidly 
Private equity investment in AI start-ups accelerated from 2016, after five years of steady increases. Private equity investment doubled from 2016 to 2017, reaching USD 16 billion in 2017. AI start-ups attracted 12% of worldwide private equity investments in the first half of 2018, reflecting a significant increase from just 3% in 2011 in a trend seen across all 16 major economies. These investments are usually large, multi-million dollar deals. With maturing technologies and business models, AI is progressing towards wide roll-out. 

AI applications abound, from transport to science to health 

AI applications are experiencing rapid uptake in a number of sectors where it is possible for them to detect patterns in large volumes of data and model complex, interdependent systems to improve decision making and save costs. 
- In the transport sector, autonomous vehicles with virtual driver systems, highdefinition maps and optimised traffic routes all promise cost, safety, quality of life and environmental benefits. • Scientific research uses AI to collect and process large-scale data, to help reproduce experiments and lower their cost, and to accelerate scientific discovery. 
- In healthcare, AI systems help diagnose and prevent disease and outbreaks early on, discover treatments and drugs, propose tailored interventions and power selfmonitoring tools. 
- In criminal justice, AI is used for predictive policing and assessing reoffending risk. • Digital security applications use AI systems to help automate the detection of and response to threats, increasingly in real time. 
- AI applications in agriculture include crop and soil health monitoring and predicting the impact of environmental factors on crop yield. 
- Financial services leverage AI to detect fraud, assess credit-worthiness, reduce customer service costs, automate trading and support legal compliance. 
- In marketing and advertising, AI mines data on consumer behaviour to target and personalise content, advertising, goods and services, recommendations and prices. 

Trustworthy AI is key to reaping AI’s benefits 

Alongside benefits, AI raises public policy considerations and efforts are needed to ensure trustworthy, human-centred AI systems. AI – notably some types of ML – raises new types of ethical and fairness concerns. Chief among them are questions of respect for human rights and democratic values, and the dangers of transferring biases from the analogue into the digital world. Some AI systems are so complex that explaining their decisions may be impossible. Designing systems that are transparent about the use of AI and are accountable for their outcomes is critical. AI systems must function properly and in a secure and safe manner. National policies are needed to promote trustworthy AI systems, including those that encourage investment in responsible AI research and development. In addition to AI technology and computing capacity, AI leverages vast quantities of data. This increases the need for a digital environment that enables access to data, alongside strong data and privacy protections. AIenabling ecosystems can also support small and medium-sized enterprises as they navigate the AI transition and ensure a competitive environment. AI will change the nature of work as it replaces and alters components of human labour. Policies will need to facilitate transitions as people move from one job to another, and ensure continuous education, training and skills development.

AI is a growing policy priority for all stakeholders 

In view of the transformative benefits of AI as well as its risks, AI is a growing policy priority for all stakeholders. Many countries have dedicated AI strategies that consider AI as an engine of growth and well-being, seek to educate and recruit the next generation of researchers, and consider how best to address AI challenges. Non-governmental stakeholders – business, technical organisations, academia, civil society and trade unions – and international bodiesincluding the G7, G20, OECD, European Commission and United Nations and are also taking action. In May 2019 the OECD adopted its Principles on Artificial Intelligence, the first international standards agreed by governments for the responsible stewardship of trustworthy AI, with guidance from a multi-stakeholder expert group


### 6. AI applications

This chapter illustrates opportunities in several sectors where artificial intelligence (AI) technologies are seeing rapid uptake, including transport, agriculture, finance, marketing and advertising, science, healthcare, criminal justice, security the public sector, as well as in augmented and virtual reality applications. In these sectors, AI systems can detect patterns in enormous volumes of data and model complex, interdependent systems to generate outcomes that improve the efficiency of decision making, save costs and enable better resource allocation.
AI in transportation with autonomous vehicles Artificial intelligence (AI) systems are emerging across the economy. However, one of the most transformational shifts has been with transportation and the transition to self-driving, or autonomous vehicles (AVs).

#### AI in the public sector 
The potential of AI for public administrations is manifold. The development of AI technologies is already having an impact on how the public sector works and designs policies to serve citizens and businesses. Applications touch on areas such as health, transportation and security services. 15 Governments in OECD countries are experimenting with and implementing projects aimed at exploiting AI to better meet the needs of public-service users. They also want to enhance stewardship of their resources (e.g. increasingly saving the time civil servants spend on customer support and administrative tasks). AI tools could enhance the efficiency and quality of many public sector procedures. For example, they could offer citizens the opportunity to be engaged right up-front in the process of service design and to interact with the state in a more agile, effective and personalised way. If correctly designed and implemented, AI technologies could be integrated into the entire policy-making process, support public sector reforms and improve public sector productivity. Some governments have deployed AI systems to strengthen social welfare programmes. For instance, AI could help attain optimal inventory levels at health and social service locations. They would do this through ML technologies that analyse transaction data and make increasingly accurate replenishment predictions. This, in turn, would facilitate forecasting and policy development. In another example, AI algorithms are helping the UK government detect fraud in social benefits claims (Marr, 2018[98]).

#### AI in agriculture 
Improving accuracy of cognitive computing technologies such as image recognition is changing agriculture. Traditionally, agriculture has relied on the eyes and hands of experienced farmers to identify the right crops to pick. “Harvesting” robots equipped with AI technologies and data from cameras and sensors can now make this decision in real time. This type of robot can increasingly perform tasks that previously required human labour and knowledge. Technology start-ups are creating innovative solutions leveraging AI in agriculture (FAO, 2017[20]). They can be categorised as follows (Table 3.1): Agricultural robots handle essential agricultural tasks such as harvesting crops. Compared to human workers, these robots are increasingly fast and productive.
Crop and soil monitoring leverages computer vision and deep-learning algorithms to monitor crop and soil health. Monitoring has improved due to greater availability of satellite data (Figure 3.3). Predictive analytics use ML models to track and predict the impact of environmental factors on crop yield.

#### AI in marketing and advertising 
AI is influencing marketing and advertising in many ways. At the core, AI is enabling the personalisation of online experiences. This helps display the content in which consumers are most likely to be interested. Developments in ML, coupled with the large quantities of data being generated, increasingly allow advertisers to target their campaigns. They can deliver personalised and dynamic ads to consumers at an unprecedented scale (Chow, 2017[45]). Personalised advertising offers significant benefits to enterprises and consumers. For enterprises, it could increase sales and the return on investment of marketing campaigns. For consumers, online services funded by advertising revenue are often provided free of charge to end users and can significantly decrease consumers’ research costs. The following non-exhaustive list outlines some developments in AI that could have a large impact on marketing and advertising practices around the world: Language processing: One of the major subfields of AI that increases personalisation of ads and marketing messages is natural language processing (NLP). It enables the tailoring of marketing campaigns based on linguistic context such as social media posts, emails, customer service interactions and product reviews. Through NLP algorithms, machines learn words and identify patterns of words in common human language. They improve their accuracy as they go. In so doing, they can infer a customer’s preferences and buying intent (Hinds, 2018[46]). NLP can improve the quality of online search results and create a better match between the customer’s expectations and the ads presented, leading to greater advertising efficiency. For example, if customers searched online for a specific brand of shoes, an AI-based advertising algorithm could send targeted ads for this brand while they are doing unrelated tasks online. It can even send phone notifications when customers walk close to a shoe store offering discounts. Structured data analysis: AI’s marketing impact goes beyond the use of NLP models to analyse “unstructured data”. Because of AI, today’s online recommendation algorithms vastly outdo simple sets of guidelines or historical ratings from users. Instead, a wide range of data is used to provide customised recommendations. For instance, Netflix creates personalised suggested watching lists by considering what movies a person has watched or the ratings given to those movies. However, it also analyses which movies are watched multiple times, rewound and fast-forwarded (Plummer, 2017)

#### AI in science 
Global challenges today range from climate change to antibiotic bacterial resistance. Solutions to many of these challenges require increases in scientific knowledge. AI could increase the productivity of science, at a time when some scholars are claiming that new ideas may be becoming harder to find (Bloom et al., 2017[52]). AI also promises to improve research productivity even as pressure on public research budgets is increasing. Scientific insight depends on drawing understanding from vast amounts of scientific data generated by new scientific instrumentation. In this context, using AI in science is becoming indispensable. Furthermore, AI will be a necessary complement to human scientists because the volume of scientific papers is vast and growing rapidly, and scientists may have reached “peak reading”.5 The use of AI in science may also enable novel forms of discovery and enhance the reproducibility of scientific research. AI’s applications in science and industry have become numerous and increasingly significant. For instance, AI has predicted the behaviour of chaotic systems, tackled complex computational problems in genetics, improved the quality of astronomical imaging and helped discover the rules of chemical synthesis. In addition, AI is being deployed in functions that range from analysis of large datasets, hypothesis generation, and comprehension and analysis of scientific literature to facilitation of data gathering, experimental design and experimentation itself.

#### AI in health 
Background AI applications in healthcare and pharmaceuticals can help detect health conditions early, deliver preventative services, optimise clinical decision making, and discover new treatments and medications. They can facilitate personalised healthcare and precision medicine, while powering self-monitoring tools, applications and trackers. AI in healthcare offers potential benefits for quality and cost of care. Nevertheless, it also raises policy questions, in particular concerning access to (health) data (Section “AI in Health”) and privacy (Subsection “Personal data protection” in Chapter 4). This section focuses on AI’s specific implications for healthcare. 62 │ 3. AI APPLICATIONS ARTIFICIAL INTELLIGENCE IN SOCIETY © OECD 2019 In some ways, the health sector is an ideal platform for AI systems and a perfect illustration of its potential impacts. A knowledge-intensive industry, it depends on data and analytics to improve therapies and practices. There has been tremendous growth in the range of information collected, including clinical, genetic, behavioural and environmental data. Every day, healthcare professionals, biomedical researchers and patients produce vast amounts of data from an array of devices. These include electronic health records (EHRs), genome sequencing machines, high-resolution medical imaging, smartphone applications and ubiquitous sensing, as well as Internet of Things (IoT) devices that monitor patient health (OECD, 2015[62]).

#### AI in criminal justice 
AI and predictive algorithms in the legal system AI holds the potential to improve access to justice and advance its effective and impartial adjudication. However, concerns exist about AI systems’ potential challenges to citizen participation, transparency, dignity, privacy and liberty. This section will focus on AI advancement in the area of criminal justice, touching upon developments in other legal areas as well.

#### AI in security 
AI promises to help address complex digital and physical security challenges. In 2018, global defence spending is forecasted to reach USD 1.67 trillion, a 3.3% year-on-year increase (IHS, 2017[89]). Security spending is not limited to the public sector, however. The private sector worldwide was expected to spend USD 96 billion to respond to security risks in 2018, an 8% increase from 2017 (Gartner, 2017[90]). Recent large-scale digital security attacks have increased society’s awareness of digital security. They have demonstrated that data breaches can have far-reaching economic, social and national security consequences. Against this backdrop, public and private actors alike are adopting and employing AI technologies to adjust to the changing security landscape worldwide. This section describes two security-related areas that are experiencing particularly rapid uptake: digital security and surveillance.12,1.

### 7. International co-operation

AI initiatives are proliferating Cross-border research on AI is significant. For example, the French National Research Agency, the German Research Foundation and the Japan Science and Technology Agency have called for trilateral French-German-Japanese collaborative research on AI over three years. Many EU countries are also participating in European AI research projects and networks such as BVDA/EURobotics, the Confederation of Laboratories for Artificial Intelligence Research in Europe (CLAIRE) and the European Laboratory for Learning and Intelligent Systems (ELLIS). AI is also a priority in Horizon Europe, the European Union’s next framework programme for research and innovation.
There are numerous international co-operation initiatives at the regional level. For example, the Arab AI Working Group, formed in 2019 by the Arab League members, has four goals. First, it aims to develop a joint framework for capacity building in the Arab region. Second, it raises awareness of the opportunities and challenges of AI. Third, it trains youth to compete in AI jobs. Finally, it works to establish a common Arab Strategy, which includes a regulatory framework for AI and guidance on using AI to serve the goals of Arab countries. Meanwhile, under Egypt’s presidency in 2020, the African Union set up a working group on AI. The working group plans to create a joint capacity-building framework across the continent. This will address skills gaps and prepare African youth for future jobs; identify and initiate AI projects across Africa to serve the Sustainable Development Goals (SDGs); and establish a common AI strategy for Africa. OECD DIGITAL ECONOMY OUTLOOK 2020 © OECD 2020 285 11. ARTIFICIAL INTELLIGENCE, BLOCKCHAIN AND QUANTUM COMPUTING 11. ARTIFICIAL INTELLIGENCE, BLOCKCHAIN AND QUANTUM COMPUTING International co-operation for AI is also taking place in fora including the OECD, the Group of Seven (G7), the Group of Twenty (G20), the European Union, the Council of Europe and the United Nations Educational Scientific and Cultural Organization (UNESCO).

### 8. Quantum computing 

The theory of quantum mechanics opens a door to new technologies The theory of quantum mechanics is fundamentally different from the laws of nature commonly accepted as inarguable truths. It has peculiar features and nuances, such as the theories of superposition and non-locality. This is often explained in lay terms as particles being “in different places at the same time”. Initially founded in quantum mechanical theories, the notion of a quantum computer arose from the idea that humanity could use these more complex laws of nature to develop technology that could solve problems beyond the capacity of “normal” or “classical” computers. Quantum mechanics opens a door to a range of new technologies for different purposes. One such purpose is “sensing”, the field that uses quantum systems for high precision measurements of magnetic fields, electrical fields, gravity and temperature. Other potential targets are quantum timekeeping, global positioning, signal processing, cryptography and solutions to computational problems. This section will focus on the latter.

Quantum computers provide an advantage for specific computational tasks According to scientific consensus, a (universal) quantum computer should be programmable to perform any computational task allowed by the laws of physics. This notion can be best understood by comparing a classical computer to a calculator. A classical computer can be programmed to perform any desired task, while a calculator can only perform limited predefined calculations. The news media define a quantum computer more broadly to include machines that only perform a set of predetermined tasks. In one example of such a machine, the Canadian company D-Wave Systems commercialised the quantum annealer. This section will use the term quantum computer widely to refer to any form of quantum technology designed to perform computational tasks.
To achieve impact, a quantum computer needs sufficient computational power. 

Current quantum computers serve as a proof-of-concept that the technology can be built. However, they lack the power to offer an advantage over classical computers for any real-world application. Furthermore, errors occur frequently. This is referred to as “noise” in the computation. To distinguish the current small-scale quantum computers from ideal quantum computers, the latter will be labelled as “largescale fault-tolerant quantum computers”. 294 OECD DIGITAL ECONOMY OUTLOOK 2020 © OECD 2020 11. ARTIFICIAL INTELLIGENCE, BLOCKCHAIN AND QUANTUM COMPUTING 11. ARTIFICIAL INTELLIGENCE, BLOCKCHAIN AND QUANTUM COMPUTING Unlike some popular science reports might suggest, a quantum computer is not a magic machine that provides additional computational power. It is faster than classical computers only at performing specific tasks. As a result, it has the potential to address certain computational problems, which are intractable on the most powerful supercomputer, and any future classical computer. For other tasks, discussed below, it could provide a significant speed-up. 

Quantum computers are not the answer to all computational problems. Some tasks have good solutions on neither a classical nor a quantum computer. This class of problems is called “NP-hard” problems. An example of such tasks is the famous travelling salesman problem. One solution would be to find the shortest possible route that visits each of a number of selected cities and ends at the city of origin. One could check the length of every possible route, but this takes too long as the list grows broader and broader. As the theory suggests, quantum algorithms that tackle this problem have only a small computational benefit over classical ones (Moylett, Linden and Montanaro, 2017[51]). Other tasks that are simple on a classical computer, such as copying a piece of data, are complex and difficult on quantum computers. Therefore, quantum computers are unlikely to become machines that consumers will buy individually; instead, they will be used in combination with classical computers and purchased by governments and corporations to perform those tasks for which they offer a competitive advantage.

Quantum computing remains at an early stage for many sectors. Quantum computing holds promise for many sectors, including agriculture, energy and health care, but further research is needed. In agriculture, access to fertilisers is essential for producing enough food for a growing population. Nearly all fertilisers are made out of ammonia, which requires high heat and pressure to produce. More efficient production of ammonia (or a substitute) would make fertilisers cheaper and could save energy. Little progress has been made because the number of possible catalyst combinations to do so is infinite. While quantum computing could lead to new discoveries, algorithms for this task have not been developed yet. Improving the capacity, cost, size and charging speed of batteries is essential for renewable energy to replace fossil fuels. Batteries are needed to store solar and wind energy and to power electric cars. Many battery materials pose environmental and humanitarian risks. Various simulation algorithms for small molecules have been developed and tested on quantum computers as a proof-of-concept. However, results simply replicate those achieved on a classical computer. IBM and Daimler, as well as Mitsubishi Chemical and various start-ups, are conducting research in this area. Efficient molecular simulation could increase our understanding of the interactions and effects of drugs on a range of diseases. In future, this could consider each person’s unique genetic composition, potentially leading to more personalised medicine. As genes are unique, this process is not suitable for traditional medical experiments. In the longer term, quantum computing could provide the answer. Many other sectors would benefit from enhancement of the materials used, such as transport, aerospace, (renewable) energy, consumer goods and packaging. The design of new materials requires understanding of their structure at the atomic level. Simulation of these materials by quantum computers allows researchers to test various possibilities before building them in the lab. This makes progress cheaper and faster. Interest in quantum computers in these sectors is slower than in the chemical and pharmaceutical industry. However, Airbus has invested in quantum software and hardware, and a handful of start-ups is dedicated to relevant industry-specific software.

Source: [AI in Society OECD publication 2019](https://doi.org/10.1787/eedfee77-en)

